{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Flower_Classification_with_RF_CNN_Demo.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python2","display_name":"Python 2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.12"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7tL2HHDt_BlF","colab_type":"text"},"source":["# Classification of Flower Images\n","## A Comparison between a Conventional ML Model (e.g. Random Forest) vs. a Deep Neural Network Model (e.g. a ConvNet)"]},{"cell_type":"markdown","metadata":{"id":"NPs7ZZJb2Q5s","colab_type":"text"},"source":["\n","The benchmark dataset used for this experiment can be found in the following link:\n","\n","Dataset: Image source: (http://www.robots.ox.ac.uk/~vgg/data/flowers/17/index.html)\n","\n","After downloading data, the zip file has to be unzipped. \n","\n","This will create a folder named **dataset**. \n","Inside this folder there will be two subfolders named - **images** and **masks**. \n","\n","**images** folder will contain many images of four category of flowers - crocus, daisy, pansy and sunflower.\n","There are a total of 234 images.\n","\n","**masks** folder will contain the binary mask images corresponding to the flower images inside the **images** folder. \n","\n","The binary masks can be used to supress the background regions from the original images to take out the regions of the actual flowers.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hJnpTCr83Lb2","colab_type":"text"},"source":["# Data Preprocessing for Ease of Use\n","\n","All the images inside the **images** folder have been resized to 256x256 RGB images and put in a disk file named **flower-images-256by256.pkl**.\n","This pickle file contains a numpy array of dimension (234, 256, 256, 3) -> a total of 234 images each of dimension 256x256 with 3 color channels for RGB.\n","\n","One more numpy array is used to save the corresponding binary masks - stored in a file named **flower-masks-256by256.pkl**.\n","\n","The binary masks are used to suppress the background of the images of the flowers before extracting color histograms from the images.\n","\n","\n","Another pickle file contains the numeric codes representing the labels/categories/target-class of the flowers. This file is named as **flower-labels.pkl**.\n","\n","### Make sure all three pickle files reside in the current folder before running the rest of the code.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hV_UsF7XsNra","colab_type":"text"},"source":["## Load Data From Disk Files\n","\n","#### Image of flowers stacked as a big numpy array (integer intensity values of image pixels)\n","#### All images are resized to 256x256 images with 3 channels for RGB planes\n","#### There are a total of 234 images\n","#### \"flower-images-256by256.pkl\"  file contains a big numpy array of the following dimension 234x256x256x3\n","\n","#### \"flower-labels.pkl\"  file contains the 234 integer labels for the flowers\n","\n","#### There are 4 category of flowers labelled with integers 0, 1, 2 and 3\n","\n","#### Four category of flowers - crocus, daisy, pansy and sunflower\n","\n","#### >> 0 - crocus, 1-daisy, 2-pansy, 3-sunflower\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ALNsJSBh7pPG","colab_type":"text"},"source":["## Read all the files"]},{"cell_type":"code","metadata":{"id":"UFh4BG8S0O37","colab_type":"code","outputId":"088f75b2-bfd8-44fb-8455-9f95f5226068","executionInfo":{"status":"ok","timestamp":1565980922434,"user_tz":-330,"elapsed":2554,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import pickle\n","\n","# original flower image 256x256x3 total 234 images\n","flower_images = pickle.load(open('flower-images-256by256.pkl','rb')) \n","\n","# image mask 256x256 total 234 masks\n","flower_masks=pickle.load(open('flower-masks-256by256.pkl','rb')) \n","\n","# Label encoded numbers ...total 234 labels >> 0 - crocus, 1-daisy, 2-pansy, 3-sunflower\n","target = pickle.load(open('flower-labels.pkl','rb'))  \n","\n","print('\\n Loaded the files......')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," Loaded the files......\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ngADYUQp3s43","colab_type":"code","outputId":"8075cb84-551a-4bbd-fba7-42c27856891a","executionInfo":{"status":"ok","timestamp":1565953328377,"user_tz":-330,"elapsed":1134,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(type(flower_images))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<type 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHD4N65U36uC","colab_type":"code","outputId":"7a7d3db5-668d-4d12-cade-c18e7331a61d","executionInfo":{"status":"ok","timestamp":1565953332022,"user_tz":-330,"elapsed":1515,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["size=len(flower_images)\n","print(size)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["234\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4tGakB5ixUfI","colab_type":"text"},"source":["#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","# PART 1: Flower Image Classification with Random Forest\n"]},{"cell_type":"markdown","metadata":{"id":"BLHF8aFxu0jF","colab_type":"text"},"source":["## Import Libraries"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VTB1TQ0Q7Zb9","colab":{}},"source":["\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmu8eBz87xRr","colab_type":"text"},"source":["Random Forest and other machine learning classifiers need numeric vectors as input.\n","They generally don't work on the raw data (e.g. raw images).\n","\n","Therefore, we need to convert the raw images into **numeric vectors (hand-engineered features)**.\n","\n","In this experiment, we represent each image with a RGB histogram - which is a frequency distribution of various pixel intensities in the Red, Green and Blue channels.\n","\n","We write the following custom class for this purpose.\n"]},{"cell_type":"code","metadata":{"id":"BmuvM_pY05Ij","colab_type":"code","colab":{}},"source":["\n","# Create RGB color histogram feature vectors\n","#------------------------------------------------------------------------------\n","\n","class RGBHistogram:\n","\tdef __init__(self, bins):\n","\t\t# Store the number of bins for the histogram\n","\t\tself.bins = bins\n","\n","\tdef describe(self, image, mask = None):\n","\t\t# Compute a 3D RGB histogram and normalize so that images\n","\t\t# with the same content will have roughly the same histogram\n","\t\thist = cv2.calcHist([image], [0, 1, 2], mask, self.bins, [0, 256, 0, 256, 0, 256])\n","\t\tcv2.normalize(hist, hist)\n","\n","\t\t# Return 3D histogram as a flattened array\n","\t\treturn hist.flatten()\n","\n","\n","#------------------------------------------------------------------------------\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rfau4XV50k4W","colab_type":"code","colab":{}},"source":["\n","# Initialize the image descriptor\n","desc = RGBHistogram([8, 8, 8])\n","\n","data=[]\n","\n","for i in range(size):\n"," image=np.reshape(flower_images[i], (256, 256,3))   \n"," mask=np.reshape(flower_masks[i], (256, 256))   \n","\n"," features = desc.describe(image, mask)\n"," data.append(features)\n","\n","#print(len(data))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zRmeZs8u8i-c","colab_type":"text"},"source":["## Import Necessary Library for Machine Learning and Classification Metrics"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_6unQ7bQGxEW","colab":{}},"source":["## Classification of Flower images into different classes\n","\n","# import the necessary packages for Machine Learning\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_zYi4ZWS8sI8","colab_type":"text"},"source":["## Split Data into Training and Test Set"]},{"cell_type":"code","metadata":{"id":"rEWxg5ud0qYh","colab_type":"code","colab":{}},"source":["# Construct the training and testing splits\n","# Keep 70% for training, 30% for testing\n","(trainData, testData, trainTarget, testTarget) = train_test_split(data, target, test_size = 0.3, random_state = 42)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S00iVhns85yG","colab_type":"text"},"source":["## Create a Random Forest ML Model"]},{"cell_type":"code","metadata":{"id":"70rcnLjS0vg2","colab_type":"code","colab":{}},"source":["# Initialize and Train the RandomForest Classifier\n","model_rf = RandomForestClassifier()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u88dc6-b9ESX","colab_type":"text"},"source":["## Train the Model on Training Data"]},{"cell_type":"code","metadata":{"id":"ZhtBoKIf9C92","colab_type":"code","outputId":"015539e8-e0f4-4fca-85c6-28c7a6c7958f","executionInfo":{"status":"ok","timestamp":1565952453353,"user_tz":-330,"elapsed":2575,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["model_rf.fit(trainData, trainTarget)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n","            max_depth=None, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=1, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False)"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"exUZKzvP9Ij5","colab_type":"text"},"source":["## Evaluate the RF Model on Test Data"]},{"cell_type":"code","metadata":{"id":"nyjiCoPf0zPq","colab_type":"code","outputId":"017798c7-d32a-4829-f69f-3732e36e832d","executionInfo":{"status":"ok","timestamp":1565952453356,"user_tz":-330,"elapsed":2567,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"source":["# Evaluate the classifier\n","print('\\n Classification Report : \\n')\n","print(classification_report(testTarget, model_rf.predict(testData), target_names = ['crocus', 'daisy', 'pansy', 'sunflower']))\n","\n","print('\\n\\n Confusion Matrix : \\n')\n","print(confusion_matrix(testTarget, model_rf.predict(testData)))\n","\n","print('\\n\\n Classification Acccuracy : \\n')\n","print(accuracy_score(testTarget, model_rf.predict(testData))*100)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," Classification Report : \n","\n","              precision    recall  f1-score   support\n","\n","      crocus       0.31      0.42      0.36        12\n","       daisy       0.79      0.73      0.76        15\n","       pansy       0.79      0.75      0.77        20\n","   sunflower       1.00      0.92      0.96        24\n","\n","   micro avg       0.75      0.75      0.75        71\n","   macro avg       0.72      0.70      0.71        71\n","weighted avg       0.78      0.75      0.76        71\n","\n","\n","\n"," Confusion Matrix : \n","\n","[[ 5  3  4  0]\n"," [ 4 11  0  0]\n"," [ 5  0 15  0]\n"," [ 2  0  0 22]]\n","\n","\n"," Classification Acccuracy : \n","\n","74.64788732394366\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IpYuZ2TtvEuN","colab_type":"text"},"source":["\n","\n","# PART 2 : Classify the Raw Flower Images with Convolutional Neural Network\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sv8W9Dwiuxlm","colab_type":"text"},"source":["\n","#### Now we will see, how a Convolutional Neural Network will take the raw flower images as input and classify them. \n","\n","#### Note that, we are not explicitly converting the images into numeric vectors.\n","#### The ConvNet is given the **raw pixel values as input**.\n","\n","#### The ConvNet automatically extracts meaningful features from these flower images and is able to distinguish one type of flower from another.\n"]},{"cell_type":"markdown","metadata":{"id":"dKfK05dV-ApK","colab_type":"text"},"source":["## Build a ConvNet Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x2zA3yhlx4sh","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Convolution2D, Conv2D, MaxPooling2D, Dropout, Flatten\n","  \n","def create_CNN_Model(input_shape, numClasses):\n","    model = Sequential()\n","    model.add(Conv2D(16, 3, 3, border_mode='same', activation='relu', input_shape = input_shape))\n","    model.add(Conv2D(16, 3, 3, border_mode='same', activation='relu'))\n","\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","  \n","    model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","    model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","  \n","    model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","    model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","    model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    \n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(numClasses, activation='softmax'))\n","  \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DBV4uUnPGUib","colab":{}},"source":["import pickle\n","\n","\n","data = pickle.load(open('flower-images-256by256.pkl','rb'))\n","\n","#target = pickle.load(open('flower-labels.pkl','rb'))\n","\n","# Note: we are no more using the Binary masks......"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjbhG7n5wQbY","colab_type":"text"},"source":["### Splitting Data and Convert samples into Float\n","\n","#### One-Hot-Encode the Output Labels"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vAZA9q7t7Vv4","outputId":"cf6aef49-4f97-496e-9d83-cfce0164d455","executionInfo":{"status":"ok","timestamp":1565952577722,"user_tz":-330,"elapsed":2028,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","\n","# Split data into training and test set\n","X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3)\n","\n","\n","# Convert to Float and Normalize inputs from 0-255 to 0.0-1.0\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","\n","# One-Hot-Encode output labels\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","\n","\n","# Count the number of distinct classes available\n","num_classes = y_test.shape[1]\n","\n","print('\\n Number of distinct classes = {}'.format(num_classes))\n","\n","# Print the class labels after one-hot-encoded transformation \n","#print('\\n y_train = {}'.format(y_train))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," Number of distinct classes = 4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wHASLiEGwzqM","colab_type":"text"},"source":["## Parameter Setting "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YPRSpcVex67y","colab":{}},"source":["# Set this parameter\n","input_shape = (256, 256, 3)\n","\n","batch_size = 16\n","epochs = 50  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fVKz2bgO-rB0","colab_type":"text"},"source":["### Create the CNN Model"]},{"cell_type":"code","metadata":{"id":"abBCPrKf-nNd","colab_type":"code","outputId":"3a7f0798-a5ca-4765-b6d4-42a8e957d679","executionInfo":{"status":"ok","timestamp":1565952577726,"user_tz":-330,"elapsed":1996,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","cnn_model = create_CNN_Model(input_shape, num_classes)\n","cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","print(cnn_model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(256, 256,...)`\n","  \n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")`\n","  import sys\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n","  if sys.path[0] == '':\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n","  del sys.path[0]\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")`\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")`\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_39 (Conv2D)           (None, 256, 256, 16)      448       \n","_________________________________________________________________\n","conv2d_40 (Conv2D)           (None, 256, 256, 16)      2320      \n","_________________________________________________________________\n","max_pooling2d_20 (MaxPooling (None, 128, 128, 16)      0         \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 128, 128, 16)      0         \n","_________________________________________________________________\n","conv2d_41 (Conv2D)           (None, 128, 128, 32)      4640      \n","_________________________________________________________________\n","conv2d_42 (Conv2D)           (None, 128, 128, 32)      9248      \n","_________________________________________________________________\n","max_pooling2d_21 (MaxPooling (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","dropout_26 (Dropout)         (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","conv2d_43 (Conv2D)           (None, 64, 64, 64)        18496     \n","_________________________________________________________________\n","conv2d_44 (Conv2D)           (None, 64, 64, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_22 (MaxPooling (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","dropout_27 (Dropout)         (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_45 (Conv2D)           (None, 32, 32, 128)       73856     \n","_________________________________________________________________\n","conv2d_46 (Conv2D)           (None, 32, 32, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_23 (MaxPooling (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","dropout_28 (Dropout)         (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 32768)             0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 512)               16777728  \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 4)                 2052      \n","=================================================================\n","Total params: 17,073,300\n","Trainable params: 17,073,300\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2KspBH6I-0Sn","colab_type":"text"},"source":["## Train the Model on Training Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qn52D9a8yVnn","outputId":"f4d0029b-b24f-4b39-910b-9d63c2d4ad4a","executionInfo":{"status":"ok","timestamp":1565952696575,"user_tz":-330,"elapsed":39115,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = cnn_model.fit(X_train, y_train, batch_size, epochs, verbose=1, validation_data=(X_test, y_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 163 samples, validate on 71 samples\n","Epoch 1/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.4745 - acc: 0.8405 - val_loss: 1.4718 - val_acc: 0.7183\n","Epoch 2/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.3389 - acc: 0.8528 - val_loss: 1.2883 - val_acc: 0.7042\n","Epoch 3/50\n","163/163 [==============================] - 1s 4ms/step - loss: 0.3221 - acc: 0.8773 - val_loss: 1.2452 - val_acc: 0.6620\n","Epoch 4/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.7894 - acc: 0.7301 - val_loss: 1.0839 - val_acc: 0.6338\n","Epoch 5/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.3018 - acc: 0.8957 - val_loss: 2.0347 - val_acc: 0.6761\n","Epoch 6/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.3467 - acc: 0.8957 - val_loss: 1.1471 - val_acc: 0.7183\n","Epoch 7/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.3016 - acc: 0.8957 - val_loss: 1.5307 - val_acc: 0.7324\n","Epoch 8/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.2188 - acc: 0.9202 - val_loss: 1.1515 - val_acc: 0.7324\n","Epoch 9/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1809 - acc: 0.9387 - val_loss: 1.3241 - val_acc: 0.7465\n","Epoch 10/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.2085 - acc: 0.9325 - val_loss: 2.0985 - val_acc: 0.7324\n","Epoch 11/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.2744 - acc: 0.9264 - val_loss: 2.9531 - val_acc: 0.6620\n","Epoch 12/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.4410 - acc: 0.9141 - val_loss: 2.5667 - val_acc: 0.7606\n","Epoch 13/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.5657 - acc: 0.8712 - val_loss: 1.0705 - val_acc: 0.7606\n","Epoch 14/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1929 - acc: 0.9448 - val_loss: 1.3755 - val_acc: 0.7465\n","Epoch 15/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1137 - acc: 0.9571 - val_loss: 1.7082 - val_acc: 0.7183\n","Epoch 16/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.5912 - acc: 0.8957 - val_loss: 1.4592 - val_acc: 0.7606\n","Epoch 17/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.6598 - acc: 0.7730 - val_loss: 1.0759 - val_acc: 0.7465\n","Epoch 18/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.2056 - acc: 0.9325 - val_loss: 4.6239 - val_acc: 0.5634\n","Epoch 19/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.7480 - acc: 0.8896 - val_loss: 1.4446 - val_acc: 0.7887\n","Epoch 20/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1048 - acc: 0.9509 - val_loss: 1.4537 - val_acc: 0.7746\n","Epoch 21/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1238 - acc: 0.9632 - val_loss: 1.4625 - val_acc: 0.7606\n","Epoch 22/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1889 - acc: 0.9693 - val_loss: 2.0229 - val_acc: 0.7324\n","Epoch 23/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.5282 - acc: 0.9018 - val_loss: 1.0484 - val_acc: 0.7606\n","Epoch 24/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0552 - acc: 0.9816 - val_loss: 2.2225 - val_acc: 0.7324\n","Epoch 25/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0428 - acc: 0.9816 - val_loss: 1.6057 - val_acc: 0.7606\n","Epoch 26/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1631 - acc: 0.9509 - val_loss: 2.2637 - val_acc: 0.7183\n","Epoch 27/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.2464 - acc: 0.9509 - val_loss: 1.7381 - val_acc: 0.7606\n","Epoch 28/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0228 - acc: 0.9877 - val_loss: 1.7954 - val_acc: 0.7465\n","Epoch 29/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0620 - acc: 0.9877 - val_loss: 4.8575 - val_acc: 0.6056\n","Epoch 30/50\n","163/163 [==============================] - 1s 5ms/step - loss: 1.0097 - acc: 0.8896 - val_loss: 1.8828 - val_acc: 0.6901\n","Epoch 31/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0972 - acc: 0.9816 - val_loss: 2.2961 - val_acc: 0.7606\n","Epoch 32/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0451 - acc: 0.9816 - val_loss: 2.2639 - val_acc: 0.7324\n","Epoch 33/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0738 - acc: 0.9632 - val_loss: 2.1742 - val_acc: 0.7324\n","Epoch 34/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 1.5667 - val_acc: 0.7606\n","Epoch 35/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 1.8255 - val_acc: 0.7746\n","Epoch 36/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.4301 - acc: 0.9080 - val_loss: 2.3824 - val_acc: 0.6338\n","Epoch 37/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0687 - acc: 0.9693 - val_loss: 3.0547 - val_acc: 0.7324\n","Epoch 38/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1885 - acc: 0.9816 - val_loss: 3.9814 - val_acc: 0.6197\n","Epoch 39/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.7364 - acc: 0.8834 - val_loss: 1.9622 - val_acc: 0.7183\n","Epoch 40/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0820 - acc: 0.9755 - val_loss: 2.1733 - val_acc: 0.7183\n","Epoch 41/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 2.3166 - val_acc: 0.7042\n","Epoch 42/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1059 - acc: 0.9939 - val_loss: 2.5323 - val_acc: 0.7465\n","Epoch 43/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1946 - acc: 0.9693 - val_loss: 3.0650 - val_acc: 0.7042\n","Epoch 44/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0123 - acc: 0.9939 - val_loss: 3.0158 - val_acc: 0.7324\n","Epoch 45/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.2031 - acc: 0.9632 - val_loss: 3.0770 - val_acc: 0.6761\n","Epoch 46/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.0160 - acc: 0.9939 - val_loss: 3.0719 - val_acc: 0.7183\n","Epoch 47/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.4292 - acc: 0.9509 - val_loss: 2.6020 - val_acc: 0.6901\n","Epoch 48/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.1984 - acc: 0.9755 - val_loss: 2.7249 - val_acc: 0.6901\n","Epoch 49/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.7372 - acc: 0.9141 - val_loss: 2.1382 - val_acc: 0.6620\n","Epoch 50/50\n","163/163 [==============================] - 1s 5ms/step - loss: 0.6218 - acc: 0.9448 - val_loss: 2.2132 - val_acc: 0.7324\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JsqeulcQ-8PB","colab_type":"text"},"source":["## Evaluate the CNN on Test Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ip-p7K0KyW2Q","outputId":"2788b868-9189-4b16-a6ed-aa4a7b3048a9","executionInfo":{"status":"ok","timestamp":1565952707251,"user_tz":-330,"elapsed":1203,"user":{"displayName":"Soharab Hossain Shaikh","photoUrl":"https://lh4.googleusercontent.com/-LbXWDtefAxw/AAAAAAAAAAI/AAAAAAAAAFA/hqqrSuIIIIc/s64/photo.jpg","userId":"01930321339313069359"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["loss, accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)\n","\n","print(\"\\n Loss after training for {} epochs = {}\".format(epochs, loss))\n","\n","print(\"\\n Accuracy on validation set = {}\".format(accuracy*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," Loss after training for 50 epochs = 2.21320889869\n","\n"," Accuracy on validation set = 73.2394367037\n"],"name":"stdout"}]}]}